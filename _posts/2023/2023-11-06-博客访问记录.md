---
layout: post
title: 博客访问记录
date: 2023-11-06 20:26:00 +00:00
category: 工作和学习
tags:
  - Geek
  - CloudFlare
slug: bo-ke-fang-wen-ji-lu
---
## 序言

看自己写博客已经20多年了, 生活了半辈子都在写博客. 有了微博和微信之后, 博客的频率有些下降, 不过也好. 博客可以写一些长篇大论和深入的东西, 而微博和微信更适合写一些短小精悍的东西.

自从把博客改成了静态网页之后, 好处自然是一堆html文件随便放, 但缺点是所有需要服务端程序配合的功能都做不了, 譬如评论, 访问记录等等. 评论可以用第三方的评论系统, 访问记录可以用第三方的访问记录, 但是这些都不是自己的, 也不是很方便. 譬如CloudFlare自己就有自己的访问记录, 但是数据不是很全, 很难导出, 而且只能保留一段时间. 于是就想自己写一个访问记录的功能, 用来记录博客的访问记录.

## 方法

我最初用CloudFlare的worker功能写了个Serverless的访问记录程序, 把数据存在CloudFlare的SQLite数据库里. 但我后来发现CloudFlare的worker功能被GFW给墙了. 整个域名 (*.workers.dev) 没法在国内访问, 不知道为啥, 是不是有人用来翻墙. 于是我就放弃了CloudFlare的worker功能, 转而用自己的程序来记录访问记录.

我用Python写了一个简单的访问记录程序, 用来记录博客的访问记录. 并且把它放在GitHub上开源了:

[Logger](https://github.com/cszhe/cszhe-logger)

程序很简单, 就是一个URL, host在oracle免费的虚拟机上, 然后把这个URL内嵌到博客的模板里. 它会把访问这个URL的IP用ipinfo.io的API获取更多信息(譬如国家, 所在地, 经纬度, 网络提供商等)放在MariaDB数据库里. 然后用Grafana来展示这些数据.

其实这样统计不是非常科学. 主要有两个问题:

- False Negative (漏报): 如果客户端禁用了JavaScript, 或者JS不正常, 那么访问记录就记不下来, 这对很多爬虫来说是很正常的.
- False Positive (误报): 如果你直接访问那个URL, 那么也会被记录, 但是这个URL是没有意义的, 也不是博客的内容.

总之大差不差吧, 有些数据总比没有好.

## 结果

我用Grafana来展示这些数据, 主要从3个方面来看:

### 概要

![图 daily](/uploads/2023/logger-daily.png)

一个月一共6000个访问量, 200个访问量每天. 感觉还不错, 但是其实爬虫有相当的数量, 我们之后再分析. 从这个图可以看出, 有些天访问量很高, 有些天访问量很低, 多的有1000多个每天, 少的时候只有10来个访问量每天. 这是正常的, 有些天我可能写了一篇文章, 很多天我可能都没写.

![图 page](/uploads/2023/logger-page.png)

这个图是按网页访问的记录. 访问最多的是首页. 这个也是正常的, 因为首页是默认打开的, 有些人可能就看了首页就走了. 其次是博客的文章, 文章访问量最多的居然是我大概10年前写的一篇文章, 

[普林斯顿大学参观记]({% post_url 2015/2015-08-31-普林斯顿大学参观记 %})

这篇文章是我之前在美国参会的时候去普林斯顿大学参观写的. 之所以访问量高, 是因为这篇文章被Google给索引了, 如果你谷歌用中文搜索“普林斯顿参观”, 这篇文章的排名挺靠前的. 我估计有很多人都是通过谷歌搜索来访问的, 然后把这篇文章当攻略看了. 早知道我好好写写, 防止误导了别人. 

![图 google search](/uploads/2023/logger-princeton.png)

图: 谷歌搜索的结果

### 地理信息

第二项是访问的地理信息. 根据IP地址来反推经纬度地理位置已经很成熟了. 所以用Grafana把所有的访问展示在世界地图上是很容易的事情, 还挺壮观的. 如下图:

![图 Geolocation](/uploads/2023/logger-geo.png)

这个图, 基本上体现出来世界互联网发达程度了: 北美几乎连成了一片(主要是谷歌的数据中心吧), 东亚也不错, 欧洲也还行(我怀疑欧洲有几个国家是VPN翻墙或者是Web代理的出口, 并不是用户真正的IP), 但是南美和非洲就没有访问量了. 大洋洲网络并不发达, 但是因为我写了很多新西兰的文章, 所以也有一些访问量.

如果要分析具体的数据, 那就看这个图吧: 左面是去重复的IP, 右面是不去重复的IP. 访问前5名是: 美国, 中国, 新西兰, 澳大利亚和加拿大.  

![图 country](/uploads/2023/logger-country.png)

无论从独立IP还是重复IP来看, 美国访问量都是最多的. 其次是中国和新西兰, 一个重复访问量第二, 一个独立访问量第二. 然后接下来几个国家要么华人多, 要么跟新西兰地理接近. 

### 客户端信息

客户端信息是通过解析User Agent数据. 当然这个也是不准的. 因为客户端可以随意伪造User Agent字符串来骗服务器. 我之前就猜到有很多爬虫, 但是没有具体的统计, 直到解析了客户端的User-Agent才知道具体的数据. 如图所示:

![图 UA](/uploads/2023/logger-ua.png)

Python的那个library汇报说有30%的是BOT, 但是我觉得可能不止. 因为Bot可以完全隐闭成普通用户的访问, 所以仅供参考. 按Bot的来源:

- Google: 1707
- Bing:  11
- Baidu:  7
- Apple:  2
- Yisou:  1
- Yandex:  1

谷歌搜索怪不得强, 网站都给捅成了筛子. 国内的搜索引擎都不怎么样, 估计是因为我没有备案, 所以属于非法境外网站, 不给收录. 奇葩的是还有一个来自俄罗斯搜索引擎的访问.


## 结束语

好几次想把博客关了, 估计没人看, 维护还要花钱, 主要是域名等. 看来你不经意的一些事情都在潜移默化的影响别人, 譬如那篇普林斯顿大学参观文章. 我没想到这么多人看, 看来保留博客还是有必要的. 也算对自己的一些鞭策吧.


## 更新: 2024-08-14

大概半年之后, 终于所有的洲都有了数据. 看着这个地图, 感觉还是挺壮观的.

![图 Geolocation](/uploads/2023/logger-geo2.png)

