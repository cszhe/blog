---
layout: post
title: 驱赶AI Agent当牛马
date: 2026-02-18 10:15
category: 工作和学习
tags:
  - 人工智能
  - Geek
  - Agent
slug: qu-gan-ai-agent-dang-niu-ma
---

## 前言

三年前GPT刚出来, 我写过一篇文章, 叫[ChatGPT编写俄罗斯方块]({% post_url 2023/2023-07-03-chatgpt编写俄罗斯方块 %}). 当年还没有什么Agent, 只能让ChatGPT写代码, 然后自己把代码复制到IDE里运行. 但是这几年AI的发展真是日新月异, 现在已经有了很多Agent了. 这些Agent可以自己去搜索资料, 可以自己去写代码, 不会了还可以自己去搜索，自己去看文档, 甚至可以自己去运行代码, 看结果, 然后根据结果继续修改代码. 这就好像是有了一个AI的助理一样, 你让它帮你做一些事情, 它就会自己去完成. 这对广大于程序员来说, 真的是一个巨大的福音. 因为可以把一些重复性的工作交给AI来做, 然后就可以专注于一些更有创造性的工作了 (我不觉得AI能替代码农).

顺便吐槽一下中文翻译，Agent翻译成“智能体”，听起来就很高达上，但是到底是干什么的呢？我觉得“智能体”这个名字太抽象了，不太好理解。但是Agent这个词很多年前就已经在计算机领域存在了，以前还有人翻译成“代理”，但是这个翻译又太过于技术化了，不太适合大众理解，因为proxy也翻译成代理。其实Agent这个词在英语里是一个非常常见的词，意思就是一个代表你去做事情的东西。就像你买房子要有Agent,买房子的Agent就是代表你去找房子，去看房子，去谈价钱，去签合同的那个东西。就是“中介”么。所以我觉得Agent不如干脆就翻译成“中介”，当然这个可能太没有学术感了。同理还有Socket，翻译成“套接字”，听起来就很高大上，但是到底是干什么的呢？其实Socket这个词在英语里也是一个非常常见的词，意思就是一个插座，就是你插电器的那个东西。就像你家里有很多插座，你可以把不同的电器插到不同的插座上去。Socket就是计算机网络里的一个插座，你可以把不同的程序连接到不同的Socket上去。同理还有当年Windows编成里面的Handle，翻译成“句柄”，其实Handle这个词就是窗户把手，微软的Windows叫Windows就是因为有窗户嘛，所以Handle就是窗户把手，你拿到了这个Handle就好像拿到了这个窗户的把手一样，你就可以通过这个Handle来操作这个窗户了。总之我觉得有些翻译虽然听起来很高大上，但是其实不太好理解，反而不如直接用英文更好理解。

好了，废话少说，开始说正题吧.

## 第一次尝试

现在商业的AI Agent已经有不少了，譬如Google的Gemini Cli, Anthropic的Claude Code等等。 但是这些Agent都是商业的，虽然号称免费用，但是你接入的AI模型可不免费，除了那些少得可怜的免费额度之外，后续的使用都是要收费的。对于个人用户来说，这个成本可能就有点高了。搞不好程序没写多少，钱包随时被掏空。我之前试过Google的Gemini Cli，感觉还不错，功能也挺强大的，但是跑着跑着就提示我免费额度用完了，要我输入信用卡信息继续使用，我就放弃了。毕竟我也不想冒这个风险。

干啥这么费token呢？因为我有一个博客，就是现在在写的这个了，里面有200多篇文章，是用静态的博客生成工具，基于Python的Pelican写的。已经10年了，我记得我2007年刚来新西兰的时候，那时候还没工作，正好我闲得慌，就把以前基于WordPress写的博客内容迁移到Pelican上面了。为什么选Pelican呢？因为当时我只会Python, 其它编程语言像Ruby什么的都不太会。我记得当时在图书馆里天天迁移博客，大概弄了一周吧，还写了好多辅助程序，基本弄了个差不多。没想到它能用10年。为什么又想到要迁移博客呢？因为我发现Pelican这个项目基本处于半死不活状态了，虽然还持续有更新，但是更新的频率非常低，然后基于Pelican的主题就更惨了，几乎没人做，大多数主题都是好多年前的了，相当过时。而Jekyll就不一样了，虽然它是基于Ruby的，但是它的社区非常活跃，主题也非常多，更新也非常频繁。可能最主要原因是GitHub Pages默认支持Jekyll，所以很多人都用Jekyll来写博客了。我工作中也经常用Jekyll来写文档，一些对外公开的文档，我们基本上就用Jekyll写，然后放在GitHub上面，直接用GitHub Pages来托管了。所以我也想把我的博客迁移到Jekyll上面来。

其实我第一次尝试用AI Agent来迁移博客是在一年前，用的就是Google的Gemini Cli，虽然因为token用光没有移植成功，但是它的表现还是让我很满意的。它不像ChatGPT那样基于对话给你来生成，而是你给它一个宏观的命令，譬如“把我的博客从Pelican迁移到Jekyll”，它就会自己去分析这个命令，然后自己去查看情况，自己列一个TODO list，自己去搜索资料，自己去写代码，自己去运行代码，自己去看结果，然后根据结果继续修改代码，直到把这个任务完成了。整个过程完全不需要我来干预，完全不需要我来指导它怎么做，它就能自己去完成这个任务了。虽然最后因为token用光了没有成功，但是它的表现已经让我非常满意了。

## 本次尝试

最近正好Agentic AI这个话题又火了起来，尤其是OpenClaw这个项目，火到三天改了三次名字。让AI完全控制你的电脑。我是没胆子让AI完全控制我的电脑，但是让AI来帮我写代码还是可以的，毕竟有源码控制，大不了回滚。所以我又想起来之前的这个博客迁移的事情了，就想再试一次，看看现在的AI Agent能不能帮我把博客迁移到Jekyll上面来。鉴于上次Token不够的情况，这次我决定用本地模型了。正好学校有台Dell出的DGX Spark，配置还不错。128GB unified LPDDR5x memory, NVIDIA GB10 GPU. 这是NVIDIA出的性能小怪兽，外观看起来很像那些便宜的一体机，但是它的性能却非常强大，而且架构跟苹果的基于Apple Sillicon的MacBook Pro很像，都是ARM CPU跟共享内存的CPU。下面是它的配置情况：

```bash
~$ nvidia-smi 
Thu Feb 19 11:16:29 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GB10                    On  |   0000000F:01:00.0 Off |                  N/A |
| N/A   39C    P8              3W /  N/A  | Not Supported          |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
$ lscpu | grep -i model
Model name:                              Cortex-X925
Model:                                   1
Model name:                              Cortex-A725
Model:                                   1
$ free -h
               total        used        free      shared  buff/cache   available
Mem:           119Gi       7.9Gi        15Gi       920Ki        98Gi       111Gi
Swap:           15Gi       226Mi        15Gi
```

这个机器用来跑本地的GPT-OSS，Gemma什么的模型，Token速度简直快到你怀疑人生，眼睛根本跟不上它Token的速度。用来跑Agent正合适。

硬件解决了，然后是软件。那些Claude Code啊，Gemini Cli啊，都是商业的，只能接入他们自家的模型，所以我选择用 [OpenCode](https://opencode.ai/)了。OpenCode就一个好，几乎你知道的不知道的啥模型都能接入：免费的ollama, LMStudio，付费的Gemini, Anthropic, DeepSeek，阿里巴巴，甚至是小米，都可以接入，我都不知道小米还有模型卖Token。它完全开源，而且很活跃，几乎天天都有更新，我也不知道这帮用爱发电的开发者是怎么坚持每天更新的。

我就选择了本地的模型，叫[Qwen3 Coder Next](https://ollama.com/library/qwen3-coder-next)，是千问3的一个专门针对代码的版本，我选了qwen3-coder-next:q8_0这个模型，是一个8bit量化的模型，有85GB大小，正好放进我那个128GB的内存里了。估计比默认的4bit量化的模型更强大一些。其实一开始我还尝试了直接用Gemma3，号称谷歌Gemini的开源版本，但是似乎这个模型不是给编程打造的，有些tools的调用就不太行了，后来就放弃了，转而用这个专门针对代码的模型了。




## 后记

前前后后也花了10天左右时间吧。

```bash
$ opencode stats
┌────────────────────────────────────────────────────────┐
│                       OVERVIEW                         │
├────────────────────────────────────────────────────────┤
│Sessions                                             10 │
│Messages                                          2,197 │
│Days                                                  8 │
└────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────┐
│                    COST & TOKENS                       │
├────────────────────────────────────────────────────────┤
│Total Cost                                        $0.00 │
│Avg Cost/Day                                      $0.00 │
│Avg Tokens/Session                                22.7M │
│Median Tokens/Session                              1.4M │
│Input                                            158.1M │
│Output                                           286.7K │
│Cache Read                                        68.5M │
│Cache Write                                           0 │
└────────────────────────────────────────────────────────┘


┌────────────────────────────────────────────────────────┐
│                      TOOL USAGE                        │
├────────────────────────────────────────────────────────┤
│ bash               ████████████████████ 1260 (57.9%)   │
│ read               ████████             519 (23.8%)    │
│ edit               ███                  210 ( 9.6%)    │
│ write              █                     58 ( 2.7%)    │
│ glob               █                     50 ( 2.3%)    │
│ grep               █                     50 ( 2.3%)    │
│ webfetch           █                     11 ( 0.5%)    │
│ todowrite          █                      8 ( 0.4%)    │
│ task               █                      4 ( 0.2%)    │
│ invalid            █                      3 ( 0.1%)    │
│ question           █                      2 ( 0.1%)    │
│ websearch          █                      2 ( 0.1%)    │
└────────────────────────────────────────────────────────┘
```
